%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%

\documentclass[twoside]{article}
\usepackage{graphics}
\usepackage{url}
\usepackage{amsmath}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf 6.S085 Statistics for Research Projects
                        \hfill IAP 2014} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Notes by: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}
   {\bf Disclaimer}: {\it These notes have not been subjected to the
   usual scrutiny reserved for formal publications.  They may be distributed
   outside this class only with the permission of the Instructor.}
   \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{8}{January 30}{Ramesh Sridharan and George Chen}{William Li}

Correction from last time: Kruskal-Wallis non-parametric ANOVA

Noise distribution needs to be the same across data points (need not be Gaussian)

$H_0$: median of all groups is the same

\section{Machine Learning and Predictive Analytics}

Code Blue Example

Recall: how many predicted ``positive'' / how many there were positive

False positive: how many predicted ``positive'' incorrectly

\section{Supervised Learning vs. Unsupervised Learning}

Supervised: 
\begin{itemize}
\item data is labeled
\item want to predict label for new point
\item Example: email spam classification
\begin{itemize}
\item Training data: emails labeled (manually as spam/notspam)
\item Test data: new emails (want to classify as spam/notspam)
\end{itemize}
\end{itemize}

Unsupervised:
\begin{itemize}
\item data is not labeled
\item want to find structure in the data
\end{itemize}

Notes:
\begin{itemize}
\item Features matter a lot!
\item When we can't predict well, generally it's because we don't have good features
\item Good features give huge performance gains vs. specifics of what ML algorithm is used
\end{itemize}

\section{Supervised Learning}

Two approaches: one is probabilistic, the other is not

\subsection{Probabilistic}

Specify a probabilistic model that we assume data is actually generated from

Naive Bayes (probabilistic model) for email spam classification

Idea: specify how an email's features are are generated.

\begin{enumerate}
\item Flip a biased coin: If H, new email is spam. If T, new email is notspam
\item Generate each feature value independently, dependending on whether email is spam/ham
\end{enumerate}

Notice model has parameters!

5 Numbers
\begin{enumerate}
\item Prob(email is spam)
\item Prob(``asks for password'' is True \textbar spam ), Prob( ``mentions Nigerian prince'' \textbar spam )
\item Prob(``asks for password'' is True \textbar notspam ), Prob( ``mentions Nigerian prince'' \textbar notspam )
\end{enumerate}

Training: Estimate these parameters

Testing: Prob(spam\textbar new email)

Use Bayes' Rule:

$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

New email: ( True, True, ? )

Want:

$P( \text{SPAM} | \text{( TRUE, TRUE, ? )})$

$ = \frac{P( \text{(TRUE, TRUE, ?)} | \text{SPAM} )P(\text{SPAM}) }{P( \text{(TRUE,TRUE,?)}|\text{SPAM})P(\text{SPAM}) + P(\text{}|\text{HAM})P(\text{HAM})}$






\end{document}





