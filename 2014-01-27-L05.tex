%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%

\documentclass[twoside]{article}
\usepackage{graphics}
\usepackage{url}
\usepackage{amsmath}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf 6.S085 Statistics for Research Projects
                        \hfill IAP 2014} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Notes by: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}
   {\bf Disclaimer}: {\it These notes have not been subjected to the
   usual scrutiny reserved for formal publications.  They may be distributed
   outside this class only with the permission of the Instructor.}
   \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{5}{January 24}{Ramesh Sridharan and George Chen}{William Li}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\section{Logistic Regression}

Last time:

Model: $y = X\beta + \epsilon$

This is good if there is a linear relation between $y$ and columns of $X$

What if $y$ has a non-linear pattern?

Generalized Linear Models

$y = g^{-1}(X\beta) + \epsilon$ (noise doesn't have ot be independent anymore

$g^{-1}$ --- nonlinear ``link function''

One of the most common forms: logistic regression

$g^{-1}(z) = \frac{1}{1+\exp{(-z)}}$

Logistic regression is useful when output data ($y$) is binary, or between 0 and 1

\section{Non-Parametric/Distribution-Free Statistics}

Last week: t-test and variances; we assumed normality

In general, assumed known distribution, computed p-values/confidence intervals

If we had a sample mean with unknown variances --- t distribution

Review of p-value: probability of observed statistic or something more extreme if null hypothesis is true (t value is usually the threshold, p value is the probability mass)

\subsection{Comparing distributions}

Kolmogorov-Smirnov Test
\begin{itemize}
\item Compare two distributions
\item Do two distributions look almost the same, or are they different?
\item Based on cumulative distribution functions (CDFs) For random value $x$, $F(a) = P(x<a)$
\item Empirical CDF: For any value $a$, what \% of data is $\leq a$? (the empirical CDF is a property of the data)
\end{itemize} 

Find the biggest difference in the CDF

$D = \max\limits_x | F_1(x) - F_2(x)|$

Theoretical result: if $F_1$is empirical CDF of data generated from $F_2$, $\lim_{n \rightarrow \infty} D = 0$

The Kolmogorov-Smirnov statistic is sensitive to any difference (your software package will compute it for you)

If you want to compare your data vs. normal distribution, use Shapiro-Wilk test (uses quantiles of your data and quantiles of the normal distribution)

\subsection{Wilcoxon Signed-Rank Test}

For comparing medians of two distributions (medians are less sensitive to outliers, e.g. 1,2,4,4,8,200)

For matched pairs --- two datasets where there is a correspondence, often a before/after (weight, test scores, etc.)

For each pair, $d_1$, $S_i \in \{ (\pm 1) \}$

Rank all $d_i$, compute $R_i$ (smallest to largest)

Example ranking (smallest to largest): $d_5, d_3, d_1, d_4, d_2$

$R_5 = 1, R_3 = 2, ...$

$W = | \sum\limits_i R_i |$

$W$ has a known distribution (you can compute $p$-values, confidence intervals, etc. on this)

$W$ is a measure of how different the medians are; if they are almost the same, the terms will cancel out and be zero

Example calculation will look like $-1*1 + 1*2...$

If $W$ is large, medians are different

\textbf{Mann-Whitney U Test}: Similar, but doesn't require matched pairs

\section{Resampling Methods}

\textbf{What if the test statistical distribution is unknown?}

Key idea: use the data to tell us about the distribution 

\subsection{Permutation Tests}

Used for hypothesis testing 

Used when we don't have a null hypothesis

Comparing statistic across two groups

Idea: is there anything special about the way we labeled the groups?

Example: Consider two groups, $A$ and $B$

$\bar{x}_A - \bar{x}_B = w$

How do we know whether $w$ is big or small?


\begin{itemize}
\item Relabel points: 
\begin{itemize}
\item put all $n + m$ points together
\item pick $n$ points, call it $A_1$
\item call the rest ($m$) points, $B_1$
\end{itemize}
\item Compute test statistic ($w_1 = \bar{x}_{A_1} - \bar{x}_{B_1}$)
\item Repeat for different relabelings: $W = \{ w_1, w_2, ..., w_k \}$
\end{itemize}

How unlikely is $w$ given your set of $w$ values, $W$? (Generate an empirical distribution of $W$)

Exact test: compare versus all relabelings

Monte Carlo approximation: randomly sampl erelabelings

\subsection{Permutation Test: Other Examples}

Time series analysis: (3,10,117,20,9)

Consider a random reordering: (11,9,10,20,7,3)

Compute the statistic for the actual and reordered points

The question we're asking: Is the ordering meaningful?

\subsection{Detecting Dishonest Teachers}

Two statistics developed:

\begin{itemize}
\item A: Comparing student scores to year before and year after
\item B: Pattern of ABCD responses; how similar are they?
\end{itemize}

Permutation test: permute teacher and student matches and compute null distribution

For A, compute 50th-75th percentile of values

\subsection{Bootstrap}

Data are samples from the true distribution

Wouldn't it be nice if we could get another sample?

Idea: resample from data with replacement

Key insight from 1979 bootstrapping paper: random samples out of random samples $\rightarrow$ more random samples

If data has $N$ points, resample $n$ ($n \leq N$) points with replacement

Repeat many times; this will give you multiple datasets

Purpose: understand variability $\rightarrow$ compute confidence intervals

Compute statistic $w$ on each dataset, $\{ w_1, ..., w_n \}$

Can compute the confidence interval: perhaps find 25th to 75th percentile


In machine learning, it could be used to compute the variability of estimates


\subsection{Jacknife}

Like bootstrapping, but:

Instead of bootstrapping, use all but one point, repeat for each point

Kind of like bootstrap, with $n = N-1$

It's exact instead of randomized

\section{Model Selection}

Last time: use Lasso to get sparsity in linear regression

Recall LASSO: $\min{ \sum\limits_{i} (y_i - X_i \beta )^2 + \lambda \sum\limits_{k} |\beta_k| }$

If $\lambda$ is too big, $\beta$'s will be small/zero

If $\lambda$ is too small, no sparsity

How do we pick?

\subsection{Generalization Error}

How well do models do on unseen held-out data?

Split data into three parts:

Training: for fitting model (learning concepts)

Validation: determine which model (taking practice exam/fine-tuning)

Test: evaluate for reporting (actual exam)


Error vs. Complexity:

Training: more complicated models result in lower error

Validation: sweet minimum spot

Cross-validation: divide non-test set into $k$ partitions: train on all others, validate on that one



\end{document}





